{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled14.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOX+E4hz+Q3Rk1GC3J81dtN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Buuuuli/AIPI540_Individual_Project/blob/main/test_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQgmLBWM9ufs"
      },
      "outputs": [],
      "source": [
        "def test_model(model,test_loader,device):\n",
        "    model = model.to(device)\n",
        "    # Turn autograd off\n",
        "    with torch.no_grad():\n",
        "\n",
        "        # Set the model to evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Set up lists to store true and predicted values\n",
        "        y_true = []\n",
        "        test_preds = []\n",
        "        probability = []\n",
        "        # Calculate the predictions on the test set and add to list\n",
        "        for data in test_loader:\n",
        "            inputs, labels = data[0].to(device), data[1].type(torch.LongTensor).to(device)\n",
        "            # Feed inputs through model to get raw scores\n",
        "            logits = model.forward(inputs)                     #model_resnet                                         # change net to cost_path\n",
        "            # Convert raw scores to probabilities (not necessary since we just care about discrete probs in this case)\n",
        "            probs = F.softmax(logits,dim=1)\n",
        "            # Get discrete predictions using argmax\n",
        "            preds = np.argmax(probs.cpu().numpy(),axis=1)\n",
        "            # Add predictions and actuals to lists\n",
        "            test_preds.extend(preds)\n",
        "            y_true.extend(labels)\n",
        "            \n",
        "            probability.extend(probs)\n",
        "\n",
        "\n",
        "\n",
        "        # Calculate the accuracy\n",
        "        # test_preds = np.array(test_preds)\n",
        "        # y_true = np.array(y_true)\n",
        "        test_acc = sum([test_preds[i] == y_true[i] for i in range(len(y_true))])/len(y_true)\n",
        "\n",
        "\n",
        "        \n",
        "        # Recall for each class\n",
        "        recall_vals = []\n",
        "        for i in [2,4]:\n",
        "            # print(y_true[0])\n",
        "            class_idx = [j for j in range(len(y_true)) if y_true[j].item() == i] # np.argwhere(y_true==i)\n",
        "            total = len(class_idx)\n",
        "            correct = sum([test_preds[idx]==i for idx in class_idx])\n",
        "            recall = correct / total\n",
        "            recall_vals.append(recall)\n",
        "    \n",
        "    return test_acc,recall_vals,probability"
      ]
    }
  ]
}